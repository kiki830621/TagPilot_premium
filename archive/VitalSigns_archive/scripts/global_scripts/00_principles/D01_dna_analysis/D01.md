---
id: "D01"
title: "DNA Analysis Derivation Flow"
type: "derivation"
date_created: "2025-04-07"
date_modified: "2025-05-19"
author: "Claude"
related_to:
  - "R38": "Platform Numbering Convention"
  - "R39": "Derivation Platform Independence"
  - "R41": "Derivation Folder Structure"
  - "R120": "Filter Variable Naming Convention" 
  - "S03": "Product Line Mapping Sequence"
---

# D01: DNA Analysis Derivation Flow

This document outlines the platform-independent DNA analysis derivation process, detailing the step-by-step transformation of raw sales data to analytics-ready customer DNA profiles across any sales platform and product line.

## Data Dimensions

DNA analysis operates across three key dimensions:

1. **Platform** (`platform_id`): The sales channel or marketplace (Amazon, eBay, etc.)
2. **Product Line** (`product_line_id_filter`): The category of products (jewelry, soap dispensers, etc.)
3. **Customer** (`customer_id`): The individual purchaser

Each DNA profile is uniquely identified by the combination of customer, platform, and product line filter, allowing for multi-dimensional analysis of customer behavior patterns filtered by different product categories and sales channels.

## Derivation Steps

### D01_00: Import External Raw Data
```
IMPORT external_raw_data.{sales_data} TO raw_data.df_{source}_sales
```
- Imports raw sales data from external source
- Creates initial dataframe in the raw_data schema 
- Preserves source-specific attributes for later analysis
- Tags data with source platform information
- Note: No product_line_id_filter is needed at this stage as raw data import is platform-specific

### D01_01: Cleanse Raw Data
```
CLEANSE raw_data.df_{source}_sales TO cleansed_data.df_{source}_sales
```
- Removes invalid entries
- Corrects formatting issues
- Transforms time fields to proper time format
- Standardizes text fields
- Maintains platform identification
- Note: No product_line_id_filter is needed at this stage as cleansing is applied to platform-specific data

### D01_02: Preprocess Cleansed Data
```
PREPROCESS cleansed_data.df_{source}_sales TO processed_data.df_{source}_sales
```
- Normalizes values to common units
- Applies business rules
- Enforces data type consistency
- Sets up dimensional hierarchy
- Performs required data type conversions:
  - Ensures `time` is in proper datetime format
  - Converts amount/price fields to numeric values
- Handles missing values with appropriate imputation strategies
- Validates output schema to ensure compatibility with DNA analysis
- Maintains platform_id for source tracking
- No product_line_id_filter is needed at this stage (filter introduction reserved for D01_03)

### D01_03: Standardize Processed Data

```
STANDARDIZE processed_data.df_{source}_sales TO processed_data.df_{source}_sales_standardized
```

- Performs required data type conversions:
  - ASSIGN: `customer_id`
  - ASSIGN: `payment_time`
  - ASSIGN: `lineitem_price`
  - ASSIGN: `platform_id`
- **CRITICAL: First introduction of product_line_id**
  - This is where product category information is joined
  - Joins sales data with product categorization system
  - Uses the unified product line dictionary from S03_00
  - Adds product_line_id to each sales record via join


Example:

```R
# First load the product line dictionary
df_item_profile_dictionary <- tbl(processed_data, "df_item_profile_dictionary") %>% collect()

# Then standardize sales data and join with product line information
df_amazon_sales_standardized <- df_amazon_sales %>% 
  rename(
    lineitem_price = item_price,
    payment_time = time
  ) %>% 
  mutate(
    customer_id = as.integer(as.factor(ship_postal_code))
  ) %>% 
  drop_na(customer_id) %>%
  # Add platform identifier
  mutate(
    platform_id = "amz"
  ) %>% 
  # Join with product line dictionary by ASIN
  left_join(
    df_item_profile_dictionary, 
    by = "asin"
  ) 
```

The standardization step normalizes data types, assigns consistent identifiers, and introduces the product_line_id for the first time through joining with the product line dictionary.

### D01_04: Create Customer Profile
```
CREATE PROFILE FROM processed_data.df_{source}_sales_standardized TO app_data.df_customer_profile
```
- Extracts unique customer information from transaction data 
- Creates customer profile data:
  - `customer_id`: Unique customer identifier
  - `buyer_name`: Customer name 
  - `email`: Customer email
  - Other available customer attributes
- Performs deduplication with distinct (customer_id, platform_id)
- Stores in app_data schema for application access
- Assigns platform_id to track data source
- Focuses on only the customer entity (not product line specific)
- Note: This step does not involve product_line_id_filter as it operates at the customer entity level only

Example:
```R
# Create customer profile (independent of product line)
df_customer_profile <- df_amazon_sales_standardized %>%
  mutate(
    buyer_name = as.character(customer_id),
    email = ship_postal_code
  ) %>% 
  select(customer_id, buyer_name, email, platform_id) %>%   
  distinct(customer_id, platform_id, .keep_all=TRUE) %>% 
  arrange(customer_id)

# Save customer profile to app_data
dbWriteTable(
  app_data,
  "df_customer_profile",
  df_customer_profile,
  append = TRUE
)
```

### D01_05: Create Dimensional Views
```
CREATE DIMENSIONAL_VIEWS FROM processed_data.df_{source}_sales_standardized FOR EACH product_line_id TO processed_data.df_{source}_sales_by_customer
```
- Processes each product line separately in a loop
- Creates filtered views for each product_line_id value
- Generates customer-by-date and customer-level aggregations for each product line
- Uses APPEND to combine results from all product lines
- **Critical distinction**: Maintains both product_line_id (entity property) and product_line_id_filter (filtering parameter)
- Maps and standardizes column names to required DNA function fields:
  - `customer_id`: Customer unique identifier 
  - `platform_id`: Source platform identifier
  - `product_line_id`: Original product line category 
  - `product_line_id_filter`: Product line filtering parameter
  - `time`: Transaction timestamp
  - `total_spent`: Transaction amount
  - `times`: Sequential transaction count per customer
  - `first_purchase`: First purchase timestamp
  - `last_purchase`: Last purchase timestamp
- Calculates customer-level metrics specific to each product_line_id_filter:
  - Total purchase amount (`total_spent`)
  - Purchase frequency (`times`, `f_value`)
  - Recency (`r_value`)
  - Monetary value (`m_value`)
  - Inter-purchase time in days (`ipt`)
- Performs separate aggregation for each product_line_id_filter
- Results in customer profiles segmented by product_line_id_filter

Example:
```R
# Initialize empty data frames to collect results
combined_by_customer_by_date <- data.frame()
combined_by_customer <- data.frame()

# Process each product line filter separately
for (current_product_line_id in vec_product_line_id) {
  # Filter data for this product line
  if (current_product_line_id == "all") {
    df_current_product_line <- df_amazon_sales_standardized
  } else {
    df_current_product_line <- df_amazon_sales_standardized %>%
      filter(product_line_id == current_product_line_id)
  }
  
  # Transform to customer-by-date aggregation for this product line
  df_product_line_by_customer_by_date <- df_current_product_line %>%
    group_by(customer_id, date = as.Date(payment_time)) %>%
    summarize(
      # Calculate aggregations
      sum_spent_by_date = sum(lineitem_price, na.rm = TRUE),
      count_transactions_by_date = n(),
      platform_id = first(platform_id),
      product_line_id = first(product_line_id),
      .groups = "drop"
    ) %>%
    # Add filter parameter
    mutate(
      product_line_id_filter = current_product_line_id
    )
  
  # Transform to customer-level aggregation for this product line
  df_product_line_by_customer <- df_current_product_line %>%
    group_by(customer_id) %>%
    summarize(
      total_spent = sum(lineitem_price, na.rm = TRUE),
      times = n(),
      first_purchase = min(payment_time, na.rm = TRUE),
      last_purchase = max(payment_time, na.rm = TRUE),
      platform_id = first(platform_id),
      product_line_id = first(product_line_id),
      .groups = "drop"
    ) %>%
    # Calculate additional metrics
    mutate(
      ipt = as.numeric(difftime(last_purchase, first_purchase, units = "days")),
      r_value = as.numeric(difftime(Sys.time(), last_purchase, units = "days")),  # Recency
      f_value = times,  # Frequency
      m_value = total_spent / times,  # Monetary value
      product_line_id_filter = current_product_line_id  # Add filter parameter
    )
    
  # Append results to combined dataframes
  combined_by_customer_by_date <- bind_rows(
    combined_by_customer_by_date, 
    df_product_line_by_customer_by_date
  )
  
  combined_by_customer <- bind_rows(
    combined_by_customer, 
    df_product_line_by_customer
  )
}

# Save combined customer-level aggregations
dbWriteTable(
  processed_data,
  "df_amazon_sales_by_customer",
  combined_by_customer,
  append = FALSE,
  overwrite = TRUE
)

# Save combined customer-by-date aggregations
dbWriteTable(
  processed_data,
  "df_amazon_sales_by_customer_by_date",
  combined_by_customer_by_date,
  append = FALSE,
  overwrite = TRUE
)
```

### D01_06: Analyze Customer DNA
```
ANALYZE DNA OF processed_data.df_{source}_sales_by_customer FOR EACH product_line_id_filter APPEND ON app_data.df_dna_by_customer
```
- **Core usage of product_line_id_filter** to process data by product line
- Iterates through each product line filter value
- Runs analysis separately for each product line filter
- Extracts behavioral patterns specific to each product category
- Identifies preference indicators
- Calculates propensity scores
- Builds comprehensive customer DNA profile
- Uses append = TRUE for incremental updates to the database
- Maintains row-by-row updates for each product line filter
- Initializes global parameters for DNA analysis:
  - `delta`: Discount factor (0.1 default)
  - `ni_threshold`: Minimum transaction threshold (5 default)
  - Break points for segmentation:
    - `NESbreaks`: c(0.5, 1.5, Inf)
    - `Mbreaks`: seq(0, 1, 0.25)
    - `Fbreaks`: c(1, 5, 10, Inf)
    - `Rbreaks`: seq(0, 1, 0.25)
    - `CAIbreaks`: seq(0, 1, 0.25)
  - Labels for segment bins:
    - `textNESlabel`: c("E0", "S", "L")
    - `textMlabel`: c("M1", "M2", "M3", "M4")
    - `textFlabel`: c("F1", "F2", "F3")
    - `textRlabel`: c("R4", "R3", "R2", "R1")
    - `textCAIlabel`: c("CA1", "CA2", "CA3", "CA4")
- Includes special consolidated analysis for "all" product lines
- Results in unique DNA profiles for each (customer_id, platform_id, product_line_id_filter) combination
- Tracks total records processed across all product line filters

Example:
```R
# Initialize counter for total records processed
total_records_processed <- 0

# Loop through each product line filter value
for (current_product_line_filter in vec_product_line_id_filter) {
  message("Processing product line filter: ", current_product_line_filter)
  
  # Filter data for this product line filter
  filtered_customer_data <- df_amazon_sales_by_customer %>%
    filter(product_line_id_filter == current_product_line_filter)
    
  filtered_customer_by_date_data <- df_amazon_sales_by_customer_by_date %>%
    filter(product_line_id_filter == current_product_line_filter)
  
  # Run DNA analysis for this product line filter
  dna_results <- analysis_dna(filtered_customer_data, filtered_customer_by_date_data)
  
  # Add platform ID and product line filter
  dna_data_with_platform <- dna_results$data_by_customer %>% 
    mutate(
      platform_id = "amz",
      product_line_id_filter = current_product_line_filter
    )
  
  # Save to DNA database with append for incremental updates
  dbWriteTable(
    app_data,
    "df_dna_by_customer",
    dna_data_with_platform,
    append = TRUE,
    temporary = FALSE
  )
  
  # Track total records processed
  total_records_processed <- total_records_processed + nrow(dna_data_with_platform)
}

# Log completion
message("Total DNA records processed across all product line filters: ", total_records_processed)
```
```

### D01_07: Implement DNA Distribution Component
```
IMPLEMENT microDNADistribution COMPONENT USING app_data.df_dna_by_customer FILTERED BY platform_id AND product_line_id_filter
```
- Creates interactive component for DNA distribution analysis
- Implements ECDFs for key metrics (M, R, F, IPT)
- Provides histogram visualizations for Frequency and NES status
- Displays statistical summaries of DNA metrics
- Supports filtering by platform, product line, and customer segments
- Follows MP073 using plotly for interactive visualizations
- Enables identification of customer behavior patterns by product line
- Assists in outlier detection and segment analysis
- Provides business insights through visual DNA exploration
- Enables comparison between product lines and platforms

## Multi-Dimensional Analysis

The DNA analysis framework facilitates multi-dimensional analysis across three key dimensions:

### Platform-Level Analysis
- Compare customer behavior patterns across different sales platforms
- Identify platform-specific buying patterns
- Track cross-platform customer activity

### Product Line Analysis
- Analyze customer preferences by product category
- Identify high-value customers for specific product lines
- Compare buying patterns across categories
- Track migration between product categories

### Combined Dimensions
- Identify platform-specific product line performance
- Track customer journey across platforms and product categories
- Provide consolidated view with "all" product line
- Enable drill-down from aggregate to specific dimensions

## Platform Implementations

Platform-specific implementations of this derivation can be found in the respective platform directories:

- 01 (Amazon): `platforms/01/`
- 06 (eBay): `platforms/06/` 
- 07 (Cyberbiz): `platforms/07/`