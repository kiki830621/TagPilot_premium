---
id: "D04"
title: "Poisson Precision Marketing Derivation Flow"
type: "derivation"
date_created: "2025-06-06"
date_modified: "2025-06-06"
author: "Claude"
related_to:
  - "R38": "Platform Numbering Convention"
  - "MP58": "Database Table Creation Strategy"
  - "MP43": "Database Documentation"
  - "MP47": "Functional Programming"
  - "R21": "One Function One File"
  - "R69": "Function File Naming"
  - "MP81": "Explicit Parameter Specification"
  - "R49": "Apply Over Loops"
---

# D04: Poisson Precision Marketing Derivation Flow

This document outlines the complete end-to-end derivation process for creating Poisson-based precision marketing data, from raw external data to final application components. This derivation enables time-series sales analysis and demand forecasting using Poisson distribution models.

## Derivation Overview

The Poisson precision marketing derivation processes sales data across time periods, creating a complete time-series dataset that fills missing periods with zero sales. This enables accurate demand modeling and forecasting using Poisson distribution assumptions.

```
D03 ITEM PROFILES → UNIFIED DICTIONARY → SALES DATA → TIME EXPANSION → PROPERTY ENRICHMENT → APP DATA
```

The derivation leverages existing item profiles from D03 positioning analysis, consolidating them into a unified item dictionary before processing platform-specific sales data. Each step creates comprehensive time-series data with complete temporal coverage and zero-filled missing periods, essential for accurate Poisson distribution modeling.

The resulting data supports time-series visualization and Poisson-based demand forecasting models.

## Prerequisites

1. **D03_00 completed**: Item profiles must be imported by D03 positioning analysis
2. **D04_00 completed**: Item ID dictionary must be created for product_line_id mapping
3. External raw data sources must be accessible
4. Product line configuration in `app_data.parameters.product_line.csv`
5. Platform identifiers must be defined (e.g., "amz" for Amazon, "eby" for eBay, "cbz" for Cyberbiz)
6. Time unit configuration (daily, weekly, monthly) must be specified
7. For API-based platforms (e.g., Cyberbiz), valid API credentials must be configured

**Critical Dependency Order**: D04_00 (item dictionary) → D04_02 (cleansing with product_line_id mapping) → D04_03 (aggregation validation) → D04_07 (time series expansion)

## Derivation Steps

### D04_00: Import Item ID Dictionary

```snsql
CONSOLIDATE raw_data.df_all_item_profile_{product_line_id} AS processed_data.df_item_id_dictionary
```

- Consolidates existing item profiles from D03_00 into unified dictionary
- Uses pre-loaded df_platform configuration for cross-platform scanning
- Creates cross-references between different ID systems and product lines
- Standardizes item_id column across all product lines with platform-specific mapping
- Saves to processed_data schema as it represents processed/standardized data
- Enables consistent item identification across platforms
- Foundation for all subsequent joins and lookups
- Leverages item profiles already imported by D03 positioning analysis
- Scans all platforms defined in df_platform for comprehensive item coverage

### D04_01: Import Platform Sales Data

```snsql
IMPORT external_rawdata AS raw_data.df_{platform}_sales_by_order_id
```

- Imports raw sales data for a specific platform
- Platform parameter determines source (e.g., "amz", "eby", "cbz")
- Raw data includes order IDs, item IDs, timestamps, and sales quantities
- May contain sparse data (missing time periods)
- For API-based platforms:
  - Cyberbiz: Fetches orders via `/v1/orders` API, extracts line items
  - Handles pagination and rate limiting
  - Transforms order data to standardized sales format

### D04_02: Cleanse Sales Data

```snsql
CLEANSING raw_data.df_{platform}_sales_by_order_id AS cleansed_data.df_{platform}_sales_by_order_id
JOIN processed_data.df_item_id_dictionary ON {platform}_item_id
ADD product_line_id, platform
REMOVE unmatched items
```

**Critical Step: This is where product_line_id mapping occurs as part of data cleansing**

- **Data Type Validation**:
  - `quantity`: Convert to integer (for Poisson count data requirements)
  - `sale_date`: Convert to Date format
  - `total_amount`: Convert to numeric
  - Item IDs: Convert to character strings
- **Data Quality Cleansing**:
  - Removes duplicate entries
  - Standardizes timestamp formats
  - Handles missing or invalid values
  - Removes records with invalid quantities (≤ 0, NA, or non-numeric)
  - Validates Poisson distribution assumptions (discrete count data)
- **Item Dictionary Integration**:
  - **Joins with Item Dictionary**: Maps {platform}_item_id to product_line_id using D04_00 dictionary
  - **Removes Unmatched Items**: Filters out sales records without valid item mappings
  - **Adds Platform Identifier**: Adds platform column for multi-platform analysis
  - **Creates Clean Dataset**: Ensures all records have valid product_line_id
- **Output Standardization**:
  - Standardizes column names to match cross-platform format
  - Creates final standardized sales format with product_line_id
  - Ensures data quality for subsequent aggregation

### D04_03: Aggregate Sales by Item ID by Date

```snsql
VALIDATE cleansed_data.df_{platform}_sales_by_order_id HAS product_line_id
AGGREGATE AS processed_data.df_{platform}_sales_by_item_id_by_date
GROUP BY {platform}_item_id, DATE(sale_date), product_line_id
SUM quantity AS sales, total_amount AS revenue
```

**Aggregation Step: Validates D04_02 mapping and aggregates to daily item-level**

- **Validates Product Line Mapping**: Ensures all records have product_line_id from D04_02
- **Product Line Distribution Analysis**: 
  - Shows number of items and records per product line
  - Reports sales volume distribution across product lines
  - Validates mapping completeness from D04_02 cleansing
- **Aggregates to Daily Level**: Groups by item_id, sale_date, and product_line_id
- **Transforms Data Structure**: From order-level to daily item-level with product classification
- **Creates Foundation**: All downstream steps use this aggregated data

**Key Benefits**:
- **Validation Checkpoint**: Ensures D04_02 mapping was successful
- **Product Line Visibility**: Clear view of sales distribution across product lines
- **Data Quality Assurance**: Confirms product_line_id consistency throughout pipeline
- **Poisson-Ready Format**: Creates integer sales counts suitable for Poisson modeling

**Note**: Hourly analysis should be handled in separate derivation (e.g., D05_hourly_poisson)

### D04_04: Cleanse Item Properties

```snsql
CLEANSING raw_data.df_all_item_profile_{product_line_id} TO cleansed_data.all_df_item_profile_{product_line_id}
```

- D03_00 completed (item profiles must be imported first)
- Rename platform-specific item_id columns to {platform}_item_id format
- Remove duplicate records and validate data types
- Standardize character encoding and handle missing values
- Clean whitespace and convert empty strings to NA

### D04_05: Process Item Properties

```snsql
PROCESS cleansed_data.all_df_item_profile_{product_line_id} AS processed_data.all_df_item_profile_{product_line_id}
```

- D04_04 completed (cleansed item profiles required)
- Properties include brand, category, attributes
- Creates separate tables per product line
- Enables product line-specific analysis
- Set NAs for weird values including "請曼巴協助提供", "N/A", "NULL", empty strings, etc.
- Using *Missing-indicator approach* for numerical columns:
  - Create `{column}_is_missing` binary indicator columns
  - Fill NA values with column mean
- Categorical columns → dummy coding using `dummy_columns()`:
  - NA values automatically become separate dummy columns (e.g., `column_NA`)
  - Excludes from dummy processing:
    - All platform item ID columns (`{platform}_item_id`)
    - Brand column (preserved as original)
    - Time-related columns (dates, timestamps, or columns with time-related names)
  - Uses `ignore_na = FALSE` to handle missing values as separate category

### D04_06: Create Time Frame Reference

```snsql
ROWS_UPSERT range(time), time_unit FROM processed_data.df_{platform}_sales_by_item_id_by_date IN app_data.df_time_range
```

- Extracts unique time range from sales data
- Determines min and max dates automatically
- Uses daily granularity for Poisson analysis (hourly analysis in separate derivation)
- Creates complete time sequence based on detected time_unit
- Generates complete time frame with time attributes using time_Recode
- Upserts into app_data.df_time_range table
- Saves platform-specific complete time frame as app_data.df_{platform}_time_frame_complete
- Ensures all time periods are represented

### D04_07: Expand Sales Data with Complete Time Series

```snsql
CREATE app_data.df_{platform}_sales_complete_time_series EXPAND_GRID({platform}_item_id, app_data.df_{platform}_time_frame_complete) WITH sales = 0;
UPDATE sales FROM processed_data.df_{platform}_sales_by_item_id_by_date BY {platform}_item_id, time;
INCLUDE all time attributes FROM app_data.df_{platform}_time_frame_complete;
PRESERVE product_line_id FROM aggregated sales data
```

This critical step performs four operations (following KitchenMAMA pattern):

1. **Extract Item Range**:
   - Gets unique item IDs from aggregated sales data (equivalent to ASINrange in KitchenMAMA)
   - Creates item_id_range for grid expansion
   - Verifies product_line_id is present from D04_03 aggregation

2. **Create Complete Grid**:
   - Uses expand_grid({platform}_item_id=item_id_range, time_frame_complete)
   - Initializes all sales to 0 (Poisson zero-inflation requirement)
   - Ensures no missing time periods for any item
   - Creates complete item × time design matrix

3. **Add Product Line Mapping**:
   - Uses item-to-product_line_id mapping from aggregated sales data (already enriched in D04_03)
   - Preserves product_line_id information from aggregation step
   - Maintains data consistency across all time periods
   - Avoids duplicate dictionary processing

4. **Merge with Actual Sales**:
   - Merges expanded grid with actual sales using LEFT JOIN
   - Matches by {platform}_item_id and time period
   - Preserves zero sales for missing periods (not NA)
   - Includes all time attributes from complete time frame
   - Maintains data completeness validation (compares original vs expanded totals)

### D04_08: Enrich Time Series with Item Properties and Positioning Data

```snsql
CREATE app_data.df_{platform}_sales_complete_time_series_{product_line_id} 
JOIN app_data.df_{platform}_sales_complete_time_series WITH processed_data.all_df_item_profile_{product_line_id} ON {platform}_item_id
LEFT JOIN app_data.df_position ON eby_item_id = item_id AND product_line_id
EXCLUDE sales FROM df_position TO AVOID conflicts
```

This enrichment step performs four operations:

1. **Split by Product Line**:
   - Processes each product_line_id separately
   - Creates product line-specific enriched datasets
   - Enables focused analysis per product line

2. **Join with Item Properties**:
   - Joins time series with item properties using {platform}_item_id as key
   - Adds brand, manufacturer, category, price and other item attributes
   - Uses INNER JOIN to keep only items with valid properties

3. **Join with Positioning Data**:
   - Joins with app_data.df_position using eby_item_id mapping from properties
   - Adds positioning features (fm4tj6 factors, components, scores)
   - Uses LEFT JOIN to preserve all time series records
   - Excludes sales column from positioning to avoid conflicts

4. **Create Product Line Tables**:
   - Saves separate enriched tables per product line
   - Format: app_data.df_{platform}_sales_complete_time_series_{product_line_id}
   - Includes metadata: enriched_date, enrichment_version

### D04_09: Poisson Regression Analysis

```snsql
ANALYZE app_data.df_{platform}_sales_complete_time_series_{product_line_id} 
POISSON_REGRESSION(sales ~ single_predictor) FOR EACH predictor
STORE results AS app_data.df_{platform}_poisson_analysis_{product_line_id}
CREATE combined AS app_data.df_{platform}_poisson_analysis_all
```

This analysis step performs single-variable Poisson regression to avoid multicollinearity:

1. **Single-Variable Analysis Strategy**:
   - Performs separate Poisson regression for each predictor variable
   - Avoids multicollinearity issues common in multivariable models
   - Enables clear interpretation of individual factor effects
   - Provides clean coefficient estimates for each feature

2. **Predictor Variable Categories**:
   - **Time Features**: year, month, day, weekday, monthly dummies from time_Recode
   - **Numeric Predictors**: Item properties (price, rating, etc.), positioning scores
   - **Factor Predictors**: Brand, manufacturer, category, and other categorical features
   - **Excludes**: Item IDs, sales variables, and metadata columns

3. **Statistical Outputs**:
   - **Coefficients**: Log-scale effects of each predictor on sales
   - **Incidence Rate Ratios (IRR)**: Exp(coefficient) for multiplicative interpretation
   - **Confidence Intervals**: 95% CI for coefficients and IRR
   - **Model Diagnostics**: Deviance, AIC, convergence status, sample size
   - **Significance Testing**: P-values for hypothesis testing

4. **Results Storage**:
   - **Per Product Line**: `app_data.df_{platform}_poisson_analysis_{product_line_id}`
   - **Combined Results**: `app_data.df_{platform}_poisson_analysis_all`
   - **Metadata**: Analysis date, version, convergence status
   - **Ready for Dashboard**: Precomputed results enable instant visualization

## Final Data Structure

### Time Series Data Tables

The `app_data.df_{platform}_sales_complete_time_series_{product_line_id}` tables include:

### Core Time Series Data
- **{platform}_item_id**: Platform-specific item identifier
- **time**: Complete time series (no gaps)
- **sales**: Actual sales or 0 for missing periods
- **product_line_id**: Product line classification

### Time Attributes
- **year, month, day**: Date components (from time_Recode)
- **weekday**: Day names and dummy variables
- **month_1 to month_12**: Monthly dummy variables
- Additional time attributes as generated by time_Recode function

### Item Properties (from all_df_item_profile_{product_line_id})
- **brand**: Item brand
- **manufacturer**: Item manufacturer  
- **category**: Item category
- **price**: Item pricing information
- Additional item-specific attributes

### Positioning Features (from app_data.df_position, excluding sales)
- **fm4tj6 factors**: Positioning analysis factors
- **components**: Principal components from positioning analysis
- **scores**: Calculated positioning scores
- Other positioning-derived features

### Metadata
- **enriched_date**: Date when enrichment was performed
- **enrichment_version**: Version identifier for enrichment process

### Poisson Analysis Results Tables

The `app_data.df_{platform}_poisson_analysis_{product_line_id}` and `app_data.df_{platform}_poisson_analysis_all` tables include:

### Core Analysis Results
- **product_line_id**: Product line classification
- **platform**: Platform identifier (e.g., "cbz", "amz", "eby")
- **predictor**: Name of the predictor variable analyzed
- **predictor_type**: Type of predictor ("time_feature", "numeric", "factor")

### Statistical Coefficients
- **coefficient**: Log-scale coefficient from Poisson regression
- **incidence_rate_ratio**: Exp(coefficient) for multiplicative interpretation
- **std_error**: Standard error of the coefficient
- **z_value**: Z-statistic for significance testing
- **p_value**: P-value for hypothesis testing

### Confidence Intervals
- **conf_low**: Lower bound of 95% confidence interval (log-scale)
- **conf_high**: Upper bound of 95% confidence interval (log-scale)
- **irr_conf_low**: Lower bound of 95% CI for incidence rate ratio
- **irr_conf_high**: Upper bound of 95% CI for incidence rate ratio

### Model Diagnostics
- **deviance**: Model deviance (goodness of fit measure)
- **aic**: Akaike Information Criterion
- **sample_size**: Number of observations used in the model
- **convergence**: Convergence status ("converged", "failed", "no_variation", etc.)

### Analysis Metadata
- **analysis_date**: Date when analysis was performed
- **analysis_version**: Version identifier for analysis process

## Implementation Considerations

### Critical Design Decisions

1. **Product Line Mapping Strategy**: 
   - **D04_02 is the single point** for item-to-product_line_id mapping as part of data cleansing
   - Removes unmatched items during cleansing process
   - Creates clean dataset with guaranteed product_line_id coverage
   - D04_03 validates mapping completeness and provides distribution analysis

2. **Dependency Management**:
   - D04_00 (dictionary) must precede D04_02 (cleansing with mapping)
   - D04_02 performs item dictionary mapping and cleansing
   - D04_03 validates mapping and aggregates clean data
   - D04_07 uses pre-mapped and aggregated data for time series expansion

### Poisson Distribution Assumptions

1. **Zero-Inflation**: Missing periods are true zeros, not missing data
2. **Independence**: Sales events are independent across time
3. **Constant Rate**: Average rate can vary by item but is stable within periods
4. **Discrete Events**: Sales are count data (integers)

### Time Unit Selection

- **Daily**: Default granularity for D04 Poisson analysis, provides good balance of detail and sparsity
- **Hourly**: Should be handled in separate derivation (D05) due to complexity and different analytical requirements
- **Weekly/Monthly**: Aggregations can be derived from daily data as needed

### Platform-Specific Handling

Different platforms may require different:
- Time zone adjustments
- Sales aggregation methods
- Data quality thresholds
- Property mappings
- Data source types:
  - File-based: Amazon, eBay (CSV/Excel imports)
  - API-based: Cyberbiz (REST API with authentication)

### Error Prevention

- **Clean Data from Source**: D04_02 removes unmatched items during cleansing
- **Validation Checkpoint**: D04_03 validates mapping completeness from D04_02
- **Product Line Distribution**: Clear visibility of sales across product lines
- **Data Quality Assurance**: Consistent product_line_id throughout pipeline
- **Early Problem Detection**: Identifies any mapping issues at cleansing stage
- **Execution Order Enforcement**: Clear dependency requirements between steps

## Functional Implementation

Following MP47 (Functional Programming) and R21 (One Function One File):

### Import Functions
1. `fn_import_item_id_dictionary.R` - Imports item ID mappings
2. `fn_import_platform_sales_data.R` - Imports platform-specific sales
3. `fn_import_item_properties.R` - Imports item metadata
4. `fn_fetch_cyberbiz_orders.R` - Fetches orders from Cyberbiz API (httr2-based)
5. `fn_process_cyberbiz_orders_to_sales.R` - Transforms Cyberbiz orders to sales data

### Processing Functions
1. `fn_cleanse_sales_data.R` - Cleans and validates sales data
2. `fn_join_item_properties.R` - Enriches items with properties
3. `fn_create_time_frame.R` - Generates complete time sequence
4. `fn_expand_sales_grid.R` - Creates complete item × time grid
5. `fn_update_sales_values.R` - Populates actual sales values

### Utility Functions
1. `fn_validate_time_unit.R` - Ensures valid time granularity
2. `fn_calculate_poisson_parameters.R` - Estimates distribution parameters
3. `fn_detect_zero_inflation.R` - Identifies excess zeros

## Visualization Components

The Poisson marketing data supports:

1. **Time Series Charts**: Sales trends over time
2. **Demand Heatmaps**: Item × time period intensity
3. **Poisson Fit Diagnostics**: Model validation plots
4. **Forecast Visualizations**: Predicted demand with confidence intervals

## Related Principles

- **MP43 (Database Documentation)**: Schema and relationships documented
- **MP47 (Functional Programming)**: Pure functions for data processing
- **MP58 (Database Table Creation Strategy)**: Consistent table naming
- **MP81 (Explicit Parameter Specification)**: Named parameters throughout
- **R21 (One Function One File)**: Modular function organization
- **R38 (Platform Numbering Convention)**: Platform-specific identifiers
- **R49 (Apply Over Loops)**: Vectorized operations for efficiency
- **R69 (Function File Naming)**: fn_ prefix convention

## Implementation Files

### Platform-specific Scripts
- Platform implementation: `/update_scripts/{platform}_D04_*.R`
- Universal scripts: `/update_scripts/all_D04_*.R`
- Examples: 
  - All platforms: `all_D04_00.R` (item ID dictionary), `all_D04_04.R` (cleanse item properties), `all_D04_05.R` (process item properties)
  - Amazon: `amz_D04_01.R` (import), `amz_D04_02.R` (cleanse sales), `amz_D04_03.R` (aggregate sales), `amz_D04_06.R` (time frame), `amz_D04_07.R` (expand time series), `amz_D04_08.R` (enrich with properties and positioning)
  - eBay: `eby_D04_01.R` (import), `eby_D04_02.R` (cleanse sales), `eby_D04_03.R` (aggregate sales), `eby_D04_06.R` (time frame), `eby_D04_07.R` (expand time series), `eby_D04_08.R` (enrich with properties and positioning)
  - Cyberbiz: `cbz_D04_01.R` (import), `cbz_D04_02.R` (cleanse sales), `cbz_D04_03.R` (aggregate sales), `cbz_D04_06.R` (time frame), `cbz_D04_07.R` (expand time series), `cbz_D04_08.R` (enrich with properties and positioning)

### Function Implementations
- Import functions: `/global_scripts/03_import/fn_*.R`
- Processing functions: `/global_scripts/05_data_processing/fn_*.R`
- Poisson utilities: `/global_scripts/07_statistics/fn_*poisson*.R`

### Visualization Components
- Time series components: `/global_scripts/10_rshinyapp_components/timeseries/`
- Forecast components: `/global_scripts/10_rshinyapp_components/forecast/`